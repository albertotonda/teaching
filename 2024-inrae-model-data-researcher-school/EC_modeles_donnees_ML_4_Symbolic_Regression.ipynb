{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 4: Introduction to ML - White-box ML with Symbolic Regression\n",
        "We are going to play with a trivial test case of regression, using a Symbolic Regression library called PySR. As the authors of PySR apparently love pain, they decided to write their library in Julia and then create Python bindings. Expect to see some really weird outputs while executing the next two cells, but there is a high probability everything will be fine in the end."
      ],
      "metadata": {
        "id": "ZH9s6IVp9OLu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hm0VolBzWqH1"
      },
      "outputs": [],
      "source": [
        "!pip install pysr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3ttYyK_YrE7"
      },
      "outputs": [],
      "source": [
        "import pysr\n",
        "\n",
        "import sympy\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from pysr import PySRRegressor\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's create a simple dataset with five features $X_0, ... X_5$, and one output variable, y, where:\n",
        "\n",
        "$y = 2.5382 \\cdot \\cos(X_3) + (X_0)^2 - 2$\n",
        "\n",
        "This run will last a while, Symbolic Regression can be quite slow when compared to other algorithms like Random Forest. The upside is that the best equation obtained will be perfectly human readable."
      ],
      "metadata": {
        "id": "Z7Ze_3dw91s2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DjAcgtbW9T-"
      },
      "outputs": [],
      "source": [
        "# generate dataset\n",
        "np.random.seed(0)\n",
        "X = 2 * np.random.randn(100, 5)\n",
        "y = 2.5382 * np.cos(X[:, 3]) + X[:, 0] ** 2 - 2\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter([i for i in range(0, 100)], y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "default_pysr_params = dict(\n",
        "    populations=30,\n",
        "    model_selection=\"best\",\n",
        "    verbosity=0,\n",
        "    progress=False,\n",
        ")\n",
        "\n",
        "model = PySRRegressor(\n",
        "    niterations=30,\n",
        "    binary_operators=[\"+\", \"*\"],\n",
        "    unary_operators=[\"cos\", \"exp\", \"sin\"],\n",
        "    **default_pysr_params,\n",
        ")\n",
        "\n",
        "model.fit(X, y)\n",
        "\n",
        "print(\"Best compromise obtained:\", model.sympy())"
      ],
      "metadata": {
        "id": "qkW-ByYV_V73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It worked really well! What happens if we now tackle an example with some noise?"
      ],
      "metadata": {
        "id": "iHsi4SVS-6VN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "noise = np.random.randn(100) * 0.1\n",
        "y = y + noise\n",
        "\n",
        "model.fit(X, y)"
      ],
      "metadata": {
        "id": "w5pS_450AcxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interestingly, PySR does not return just a single equation, but a series of compromises between complexity and fitting. The added noise might have led the algorithm to develop extremely complex equations that also fit part of the noise. Let's check all the equations found in the end."
      ],
      "metadata": {
        "id": "Iq1-vSqLAxN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for equation in model.equations_[\"sympy_format\"] :\n",
        "  print(equation)"
      ],
      "metadata": {
        "id": "gpYt4LXwAvK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see equations that remind us of the correct one, but their terms are slightly different, and other (irrelevant) variables have been added to the equations, just because they randomly fit the noise.\n",
        "\n",
        "Let's take a look at the Pareto front of complexity vs fitting. Each point will represent a candidate equation."
      ],
      "metadata": {
        "id": "AJa6lD_iCq_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.scatter(model.equations_[\"complexity\"], model.equations_[\"loss\"])\n",
        "ax.set_xlabel(\"complexity\")\n",
        "ax.set_ylabel(\"error\")\n",
        "ax.set_title(\"Pareto front of equations, complexity vs fitting\")"
      ],
      "metadata": {
        "id": "gxao_73WC5tF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's easy to notice that, from left to right, the equations keep increasing in complexity, while only very slightly reducing error. The equation considered the 'best' is picked by a heuristic on the Pareto front, but it seems to work quite well even with some noise.\n",
        "\n"
      ],
      "metadata": {
        "id": "GXMIOpsyDV4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.sympy())\n",
        "\n",
        "# find the index of the equation in the Pareto front; it's a bit of convoluted code, but trust me on this\n",
        "index = model.equations_[model.equations_[\"sympy_format\"] == model.sympy()].index.tolist()[0]\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(model.equations_[\"complexity\"], model.equations_[\"loss\"])\n",
        "ax.scatter(model.equations_[\"complexity\"].iloc[index], model.equations_[\"loss\"].iloc[index], color='red', label=\"Model considered the best\")\n",
        "ax.set_xlabel(\"complexity\")\n",
        "ax.set_ylabel(\"error\")\n",
        "ax.set_title(\"Pareto front of equations, complexity vs fitting\")\n",
        "ax.legend(loc=\"best\")\n"
      ],
      "metadata": {
        "id": "8pUcmOzbEH1W"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}